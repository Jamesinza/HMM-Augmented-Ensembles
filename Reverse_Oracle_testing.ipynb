{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f99d8b7d-bc96-4136-aebc-7c4852e56932",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 00:07:25.484004: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750975645.505239  806947 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750975645.512037  806947 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750975645.528835  806947 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750975645.528858  806947 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750975645.528860  806947 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750975645.528862  806947 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-27 00:07:25.534134: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1750975648.565591  806947 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10260 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1750975650.252230  807058 service.cc:152] XLA service 0x7cc754008980 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1750975650.252269  807058 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2025-06-27 00:07:30.276509: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1750975650.399237  807058 cuda_dnn.cc:529] Loaded cuDNN version 90800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 62/113\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1273 - loss: 4.4875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1750975651.354071  807058 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.1306 - loss: 4.1803 - val_accuracy: 0.1925 - val_loss: 2.6842\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.0878 - loss: 3.8844 - val_accuracy: 0.1425 - val_loss: 2.7512\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.1093 - loss: 3.6708 - val_accuracy: 0.1400 - val_loss: 2.7925\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.0998 - loss: 3.7641 - val_accuracy: 0.1500 - val_loss: 2.8218\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.1291 - loss: 4.1525 - val_accuracy: 0.1350 - val_loss: 3.1497\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Reverse Oracle Flags: [ True  True  True  True  True]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(32,), output.shape=(32, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 101\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Reshape model_preds_test to (num_samples, n_models, n_classes)\u001b[39;00m\n\u001b[1;32m    100\u001b[0m model_preds_test_reshaped \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(model_preds_test, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m--> 101\u001b[0m ensemble \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ensemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_preds_test_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Evaluate Ensemble\u001b[39;00m\n\u001b[1;32m    104\u001b[0m y_pred_ensemble \u001b[38;5;241m=\u001b[39m ensemble(model_preds_test_reshaped)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[0;32mIn[1], line 74\u001b[0m, in \u001b[0;36mtrain_ensemble\u001b[0;34m(model_preds, y_true, reverse_flags, n_classes, epochs, lr)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m     73\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m ensemble(x_batch)\n\u001b[0;32m---> 74\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, ensemble\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     76\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, ensemble\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/keras/src/losses/loss.py:67\u001b[0m, in \u001b[0;36mLoss.__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m     60\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype), y_pred\n\u001b[1;32m     62\u001b[0m )\n\u001b[1;32m     63\u001b[0m y_true \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype), y_true\n\u001b[1;32m     65\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m out_mask \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mget_keras_mask(losses)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m in_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m out_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/keras/src/losses/losses.py:33\u001b[0m, in \u001b[0;36mLossFunctionWrapper.call\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m     31\u001b[0m y_true \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure_up_to(y_true, \u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m], y_true_y_pred)\n\u001b[1;32m     32\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure_up_to(y_pred, \u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], y_true_y_pred)\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/keras/src/losses/losses.py:2177\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, label_smoothing, axis)\u001b[0m\n\u001b[1;32m   2172\u001b[0m     num_classes \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcast(ops\u001b[38;5;241m.\u001b[39mshape(y_true)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], y_pred\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m   2173\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m y_true \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m label_smoothing) \u001b[38;5;241m+\u001b[39m (\n\u001b[1;32m   2174\u001b[0m         label_smoothing \u001b[38;5;241m/\u001b[39m num_classes\n\u001b[1;32m   2175\u001b[0m     )\n\u001b[0;32m-> 2177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_crossentropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2178\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\n\u001b[1;32m   2179\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/keras/src/ops/nn.py:1879\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m   1875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors((target, output)):\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CategoricalCrossentropy(\n\u001b[1;32m   1877\u001b[0m         from_logits\u001b[38;5;241m=\u001b[39mfrom_logits, axis\u001b[38;5;241m=\u001b[39maxis\n\u001b[1;32m   1878\u001b[0m     )\u001b[38;5;241m.\u001b[39msymbolic_call(target, output)\n\u001b[0;32m-> 1879\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_crossentropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/py312/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:653\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    648\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must be at least rank 1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    649\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    650\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    651\u001b[0m     )\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m--> 653\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    654\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same rank \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(ndim). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    656\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    657\u001b[0m     )\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n",
      "\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(32,), output.shape=(32, 10)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# === 1. Synthetic Data ===\n",
    "X, y = make_classification(n_samples=5000, n_features=20, n_informative=15, \n",
    "                           n_redundant=5, n_classes=10, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train_oh = encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_oh = encoder.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# === 2. Weak Base Models ===\n",
    "def make_weak_model(seed):\n",
    "    tf.random.set_seed(seed)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(20,)),\n",
    "        tf.keras.layers.Dense(16, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "n_models = 5\n",
    "base_models = [make_weak_model(seed) for seed in range(n_models)]\n",
    "\n",
    "# Train each model for only 1 epoch to make them intentionally weak\n",
    "model_preds_train = []\n",
    "model_preds_test = []\n",
    "\n",
    "for model in base_models:\n",
    "    model.fit(X_train, y_train_oh, epochs=1, verbose=0)\n",
    "    model_preds_train.append(model.predict(X_train))\n",
    "    model_preds_test.append(model.predict(X_test))\n",
    "\n",
    "# Stack predictions: (n_models, num_samples, n_classes)\n",
    "model_preds_train = np.stack(model_preds_train)\n",
    "model_preds_test = np.stack(model_preds_test)\n",
    "\n",
    "# === 3. Reverse Oracle Detection ===\n",
    "def detect_reverse_oracles(model_preds, y_true, threshold=0.48):\n",
    "    reverse_flags = []\n",
    "    for preds in model_preds:\n",
    "        acc = np.mean(np.argmax(preds, axis=1) == y_true)\n",
    "        reverse_flags.append(acc < threshold)\n",
    "    return np.array(reverse_flags)\n",
    "\n",
    "reverse_flags = detect_reverse_oracles(model_preds_test, y_test)\n",
    "print(\"Reverse Oracle Flags:\", reverse_flags)\n",
    "\n",
    "# === 4. Reverse Oracle-Aware Ensemble ===\n",
    "class ReverseOracleSoftmax(tf.keras.layers.Layer):\n",
    "    def __init__(self, reverse_flags):\n",
    "        super().__init__()\n",
    "        self.reverse_flags = tf.constant(reverse_flags, dtype=tf.bool)\n",
    "\n",
    "    def call(self, model_outputs):  # (batch, n_models, n_classes)\n",
    "        flipped = 1.0 - model_outputs\n",
    "        flipped = flipped / tf.reduce_sum(flipped, axis=-1, keepdims=True)\n",
    "        return tf.where(self.reverse_flags[tf.newaxis, :, tf.newaxis], flipped, model_outputs)\n",
    "\n",
    "class WeightedReverseEnsemble(tf.keras.Model):\n",
    "    def __init__(self, reverse_flags, n_models, n_classes):\n",
    "        super().__init__()\n",
    "        self.reverse_layer = ReverseOracleSoftmax(reverse_flags)\n",
    "        self.weights = tf.Variable(tf.ones([n_models]), trainable=True)\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "    def call(self, model_outputs):  # (batch, n_models, n_classes)\n",
    "        corrected = self.reverse_layer(model_outputs)\n",
    "        weighted = corrected * tf.nn.softmax(self.weights)[tf.newaxis, :, tf.newaxis]\n",
    "        return tf.reduce_sum(weighted, axis=1)  # (batch, n_classes)\n",
    "\n",
    "# === 5. Train Ensemble Weights ===\n",
    "def train_ensemble(model_preds, y_true, reverse_flags, n_classes=10, epochs=100, lr=0.01):\n",
    "    ensemble = WeightedReverseEnsemble(reverse_flags, model_preds.shape[1], n_classes)\n",
    "    optimizer = tf.keras.optimizers.Adam(lr)\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((model_preds, y_true)).batch(32)\n",
    "    for epoch in range(epochs):\n",
    "        for x_batch, y_batch in dataset:\n",
    "            with tf.GradientTape() as tape:\n",
    "                y_pred = ensemble(x_batch)\n",
    "                loss = loss_fn(y_batch, y_pred)\n",
    "            grads = tape.gradient(loss, ensemble.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, ensemble.trainable_variables))\n",
    "    return ensemble\n",
    "\n",
    "# Reshape model_preds_test to (num_samples, n_models, n_classes)\n",
    "model_preds_test_reshaped = np.transpose(model_preds_test, (1, 0, 2))\n",
    "ensemble = train_ensemble(model_preds_test_reshaped, y_test, reverse_flags)\n",
    "\n",
    "# Evaluate Ensemble\n",
    "y_pred_ensemble = ensemble(model_preds_test_reshaped).numpy()\n",
    "acc = np.mean(np.argmax(y_pred_ensemble, axis=1) == y_test)\n",
    "print(\"Reverse-Aware Ensemble Accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69af8554-30e3-41e6-9691-19bfaab4e4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
